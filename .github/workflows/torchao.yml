name: torchao

on:
  push:
    tags:
      - ciflow/torchao/*
  workflow_dispatch:
    inputs:
      noquant:
        description: Run noquant?
        required: false
        type: boolean
        default: true
      int8dynamic:
        description: Run int8dynamic?
        required: false
        type: boolean
        default: true
      int8weightonly:
        description: Run int8weightonly?
        required: false
        type: boolean
        default: true
      int4weightonly:
        description: Run int4weightonly?
        required: false
        type: boolean
        default: true
      autoquant:
        description: Run autoquant?
        required: false
        type: boolean
        default: true
      benchmark_configs:
        description: The list of configs used the benchmark
        required: false
        type: string
        default: torchao_huggingface_perf,torchao_timm_perf,torchao_torchbench_perf

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: true

permissions: read-all

jobs:
  linux-focal-cuda12_1-py3_10-gcc9-torchao-build:
    name: cuda12.1-py3.10-gcc9-sm80
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm80
      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9-inductor-benchmarks
      cuda-arch-list: '8.0'
      test-matrix: |
        { include: [
          { config: "torchao_huggingface_perf", shard: 1, num_shards: 3, runner: "linux.gcp.a100.large" },
          { config: "torchao_huggingface_perf", shard: 2, num_shards: 3, runner: "linux.gcp.a100.large" },
          { config: "torchao_huggingface_perf", shard: 3, num_shards: 3, runner: "linux.gcp.a100.large" },
          { config: "torchao_timm_perf", shard: 1, num_shards: 5, runner: "linux.gcp.a100.large" },
          { config: "torchao_timm_perf", shard: 2, num_shards: 5, runner: "linux.gcp.a100.large" },
          { config: "torchao_timm_perf", shard: 3, num_shards: 5, runner: "linux.gcp.a100.large" },
          { config: "torchao_timm_perf", shard: 4, num_shards: 5, runner: "linux.gcp.a100.large" },
          { config: "torchao_timm_perf", shard: 5, num_shards: 5, runner: "linux.gcp.a100.large" },
          { config: "torchao_torchbench_perf", shard: 1, num_shards: 4, runner: "linux.gcp.a100.large" },
          { config: "torchao_torchbench_perf", shard: 2, num_shards: 4, runner: "linux.gcp.a100.large" },
          { config: "torchao_torchbench_perf", shard: 3, num_shards: 4, runner: "linux.gcp.a100.large" },
          { config: "torchao_torchbench_perf", shard: 4, num_shards: 4, runner: "linux.gcp.a100.large" },
        ]}
      selected-test-configs: ${{ inputs.benchmark_configs }}
    secrets:
      HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}

  linux-focal-cuda12_1-py3_10-gcc9-torchao-test:
    name: cuda12.1-py3.10-gcc9-sm80
    uses: ./.github/workflows/_linux-test.yml
    needs: linux-focal-cuda12_1-py3_10-gcc9-torchao-build
    with:
      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm80
      dashboard-tag: noquant-${{ inputs.noquant }}-int8dynamic-${{ inputs.int8dynamic }}-int8weightonly-${{ inputs.int8weightonly }}-int4weightonly-${{ inputs.int4weightonly }}-autoquant-${{ inputs.autoquant }}
      docker-image: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-torchao-build.outputs.docker-image }}
      test-matrix: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-torchao-build.outputs.test-matrix }}
      use-gha: anything-non-empty-to-use-gha
      timeout-minutes: 720
    secrets:
      HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
